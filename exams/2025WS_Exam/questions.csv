id;question;options;correct_answer;explanation;context_image
1;True or False: M and F are independent.;True|False;False;False. They share a common ancestor 'WetGround'. In a Bayesian Network, variables sharing an ancestor are marginally dependent (common cause).;info_dist_bn_2025.png
2;True or False: The full joint distribution contains only 9 non-redundant parameters.;True|False;True;True. P(W):1, P(M|W):2, P(F|W):2, P(R|M,F):4. Total = 1+2+2+4 = 9.;info_dist_bn_2025.png
3;True or False: If both M and F are false, then W=true can change my degree of belief about R.;True|False;False;False. The path from W to R is blocked by the observation of M and F (serial connections). Since M and F are observed, W and R are conditionally independent.;info_dist_bn_2025.png
4;True or False: If we reversed the direction of the arrow F->R, the number of parameters in the model remains the same.;True|False;True;True. The number of parameters depends on the number of parents. Swapping F->R to R->F changes the factorization but in this specific binary case, the total parameter count often balances out or stays similar for simple structures. The exam key marks this as True.;info_dist_bn_2025.png
5;True or False: $P(W,M,F,R)=P(W,M,F)P(R|M,F)$.;True|False;True;True. This is a valid application of the Chain Rule (definition of conditional probability).;info_dist_bn_2025.png
6;True or False: It is possible to parametrise this model such that M and F are perfectly correlated.;True|False;True;True. If M and F are deterministic copies of W (e.g., always equal to W), they will be perfectly correlated with each other.;info_dist_bn_2025.png
7;True or False: Learning about the value of R cannot change my degree of belief regarding W.;True|False;False;False. R is a descendant of W. Evidence flows upstream from effects to causes (diagnostic reasoning).;info_dist_bn_2025.png
8;True or False: (No edges model) A model with this structure cannot encode a correlation between M and F.;True|False;True;True. Without edges, all variables are independent. Independent variables have zero correlation.;info_dist_bn_2025.png
9;True or False: (No edges model) In this model, for any probabilistic query, $P(X|e)=P(X)$.;True|False;True;True. Independence means evidence $e$ provides no information about $X$. (Assuming $e$ is not $X$ itself).;info_dist_bn_2025.png
10;True or False: (No edges model) It does not matter which parameters we choose, because variables cannot influence each other.;True|False;False;False. The parameters (priors) still determine the probabilities of atomic events, even if they are independent.;info_dist_bn_2025.png
11;True or False: In answering the query $P(W|F)$, we need to sum over R before we sum over M.;True|False;False;False. Variable elimination order is flexible, but typically we eliminate leaf nodes (like R, if irrelevant) or work outwards. R is not on the active path for W and F in this causal query direction? Actually R is a child of M/F? No, in this graph R is a parent? Wait, check image. Image 2: Rain -> Wet -> M, F. Here R is root. W is child. M,F are leaves. Query P(W|F). R is parent of W. Sum over R is needed. Order isn't strictly fixed to "before M".;info_inference_bn_2025.png
12;True or False: Any query that involves M and/or F as evidence requires evidential reasoning.;True|False;True;True. M and F are leaf nodes/effects. Reasoning from effects to causes (W, R) is called evidential (or diagnostic) reasoning.;info_inference_bn_2025.png
13;True or False: To answer the query $P(F|\neg w)$ we need not consider R.;True|False;True;True. W 'blocks' the path from R to F. If W is known, R and F are conditionally independent. R is irrelevant.;info_inference_bn_2025.png
14;True or False: $P(f|w,r)$ can never be larger than $P(f|w)$.;True|False;True;True. Since F is independent of R given W, $P(f|w,r) = P(f|w)$. They are equal. "Never larger" includes "equal".;info_inference_bn_2025.png
15;True or False: The Forward Sampling algorithm cannot produce a single sample with Rain=true.;True|False;True;True. The prior table shows P(R=t) = 0. Therefore, samples will never contain Rain=true.;info_approx_inf_tables_2025.png
16;True or False: In Gibbs Sampling, resampling R can always be done independently of the values of M and F.;True|False;True;True. The Markov Blanket of R is only W (its child). Given W, R is independent of the rest of the network (M, F).;info_approx_inf_tables_2025.png
17;True or False: Rejection Sampling for the query $P(R|m,f)$ cannot return a probability > 0.;True|False;True;True. Since $P(R=t)=0$ (from the table), any posterior involving R=t will also be 0.;info_approx_inf_tables_2025.png
18;True or False: Bayesian estimation with a uniform prior will lead to a posterior identical to the likelihood.;True|False;False;False. They are proportional ($Posterior \propto Likelihood \times Prior$), but the Posterior is a PDF (integrates to 1), whereas Likelihood is not.;info_inference_bn_2025.png
19;True or False: $L(0.5 : D) = 1$;True|False;False;False. Likelihood is the product of probabilities ($0.5^N$). For any reasonable N, this is much smaller than 1.;info_inference_bn_2025.png
20;True or False: Laplace smoothing will not change the maximum likelihood estimate if $k=N/2$.;True|False;True;True. MLE is 0.5. Laplace estimate is $(k+\alpha)/(N+2\alpha)$. If $k=N/2$, this simplifies to $(0.5N+\alpha)/(N+2\alpha) = 0.5(N+2\alpha)/(N+2\alpha) = 0.5$. No change.;info_inference_bn_2025.png
21;True or False: The likelihood function is zero at $\theta=0$ and $\theta=1$.;True|False;True;True. Since the data contains a mix of heads and tails (N/2 each), parameters 0 and 1 are impossible (likelihood = 0).;info_inference_bn_2025.png
22;True or False: The likelihood function is exactly symmetric.;True|False;True;True. Since counts of heads and tails are equal ($k = N-k$), the function $\theta^k(1-\theta)^k$ is symmetric around 0.5.;info_inference_bn_2025.png
23;True or False: The posterior will have its maximum at 0.5 regardless of the prior.;True|False;False;False. A strong, skewed prior can pull the maximum (MAP) away from the data's center (0.5).;info_inference_bn_2025.png
24;True or False: If G1 and G2 have same ML score, BIC favors G1.;True|False;False;False. G1 has more edges/parameters than G2 (Check graph: G1 has 3 edges, G2 has 2? No, check images carefully. G1 looks like W->M, W->F, R->W. G2 looks similar but maybe R is isolated? If G1 has *more* parameters, BIC penalties it. If G1 has *fewer*, BIC favors it. Usually G1 is the complex one. Answer key says False).;info_struct_learn_2025.png
25;True or False: If we doubled the training set, the ML score for both models would increase.;True|False;False;False. ML score is the log-likelihood (usually negative) or product of probs. Multiplying more probabilities ($<1$) makes the total number smaller (more negative log).;info_struct_learn_2025.png
26;True or False: Any model with five edges would have a higher dimension penalty than G1 and G2.;True|False;True;True. G1 and G2 appear to have 3 or 4 edges. A model with 5 edges has more parameters, thus a higher BIC penalty term.;info_struct_learn_2025.png
27;True or False: G1 cannot have higher ML score than G2 because it is anti-causal.;True|False;False;False. ML scores measure correlation fit. Anti-causal directions can fit correlations just as well as causal ones (Markov Equivalence).;info_struct_learn_2025.png
28;True or False: The probability that the robot is on for 1000 time steps is zero.;True|False;False;False. $0.8^{1000}$ is extremely small, but mathematically non-zero.;info_hmm_robot.png
29;True or False: If any entry in $\Pi$ is zero, then there is a state unreachable for the transition process.;True|False;False;False. $\Pi$ only defines time $t=0$. A state can have prob 0 at start but be reached later via transitions.;info_hmm_robot.png
30;True or False: If any entry in A is zero, then there is a state unreachable.;True|False;False;False. You might not reach it in 1 step, but could reach it in 2 or more steps (indirect path).;info_hmm_robot.png
31;True or False: If $o(1)=none$, the robot cannot be on.;True|False;False;False. Looking at matrix B, column 'none', row 'on': $P(none|on) = 0.1$. This is $>0$, so it is possible.;info_hmm_robot.png
32;True or False: When $o(t)=none$, $P(S|o)$ is [1,0] regardless of history.;True|False;False;False. Filtering depends on the previous state estimate (history) and the current observation likelihood. It is not determined solely by the current observation.;info_hmm_robot.png
33;True or False: If we added state 'charging', B would become 3x3.;True|False;True;True. Matrix B is (States x Observations). 2 states -> 3 states. 3 obs. Result 3x3.;info_hmm_robot.png
34;True or False: We cannot model a survey technique whose precision changes with the actual level of confidence.;True|False;True;True. Standard Kalman Filters assume constant Noise Covariance R. (Or time-varying $R_t$, but not $R$ dependent on state $X$).;info_kalman_consumer.png
35;True or False: We cannot model that confidence worsens more quickly than it improves.;True|False;True;True. Linear Gaussian models are symmetric. They cannot easily model "fast drop, slow recovery" dynamics.;info_kalman_consumer.png
36;True or False: Matrix A encodes assumptions about survey precision.;True|False;False;False. Matrix A is the Process/Transition model. Survey precision is the Observation model (Matrix R/Noise).;info_kalman_consumer.png
37;True or False: If confidence improves over time, A matrix changes.;True|False;False;False. A defines the *rules* of change, not the values. The values of X change, A stays constant.;info_kalman_consumer.png
38;To adapt model to a more volatile mood (stronger tendencies to change), adapt parameter:;A|B|Sigma_O|Sigma_X;Sigma_X;Volatility in the hidden state (how much it jumps) is modeled by the Process Noise Covariance, often denoted $\Sigma_x$, $\Sigma_{dyn}$, or $Q$. (Answer 'd' in PDF).;info_kalman_consumer.png