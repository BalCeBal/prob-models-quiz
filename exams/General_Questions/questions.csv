id;question;options;correct_answer;explanation;context_image
1;What is the primary purpose of Bayes' Theorem in probabilistic reasoning?;To update prior beliefs based on new evidence|To calculate the joint probability of independent events|To transform continuous variables into discrete ones|To eliminate hidden variables from a network;To update prior beliefs based on new evidence;Bayes' Theorem mathematically describes how to update the probability of a hypothesis (prior) given new evidence, yielding the posterior probability.;
2;If events A and B are conditionally independent given C, which equation holds true?;P(A, B | C) = P(A | C) P(B | C)|P(A | B, C) = P(A | B)|P(A, B) = P(A) P(B)|P(A | C) = P(B | C);P(A, B | C) = P(A | C) P(B | C);Conditional independence means that if C is known, A and B occur independently of each other.;
3;In a Bayesian Network, what does a directed edge from node X to node Y explicitly represent?;A direct probabilistic dependence of Y on X|A deterministic relationship where X causes Y|That X and Y are marginally independent|That X is a hidden variable and Y is observed;A direct probabilistic dependence of Y on X;Edges denote direct influence or dependence, which allows the joint distribution to factorize according to the graph structure.;
4;Which of the following describes a 'v-structure' (or common effect) in a Bayesian Network?;X -> Z <- Y|X <- Z -> Y|X -> Z -> Y|X <-> Z <-> Y;X -> Z <- Y;A v-structure occurs when two parent nodes share a single common child node.;
5;In a common cause structure (A <- B -> C), what happens when B is observed?;A and C become conditionally independent|A and C become conditionally dependent|The probability of B becomes 0|The network becomes cyclic;A and C become conditionally independent;Observing the common cause blocks the active path between its effects, rendering them independent.;
6;What is the phenomenon called when observing one cause of a common effect reduces the probability of a competing cause?;Explaining away|Marginalization|Causal smoothing|Likelihood weighting;Explaining away;Explaining away occurs in a v-structure when the effect is observed, and finding one cause makes the other less necessary.;
7;What defines the Markov Blanket of a node X in a Bayesian Network?;Its parents, children, and the other parents of its children|All of its ancestors and descendants|Only its direct parents|All nodes that share an undirected path with X;Its parents, children, and the other parents of its children;A node is conditionally independent of the entire rest of the network given this specific set of nodes.;
8;How many parameters are required to specify the Conditional Probability Table (CPT) for a Boolean variable with k Boolean parents?;2^k|k^2|2^(k+1)|k;2^k;For every possible combination of the k parents (which is 2^k), we must specify 1 parameter for the child (the other is 1-p).;
9;What is the primary advantage of representing a joint distribution using a Bayesian Network?;It drastically reduces the number of parameters required|It ensures that exact inference is always polynomial time|It eliminates the need for prior probabilities|It allows cycles in causal reasoning;It drastically reduces the number of parameters required;By exploiting conditional independencies, BNs avoid the exponential blowup of explicitly listing the full joint distribution.;
10;In the Variable Elimination algorithm, what mathematical operation is performed to eliminate a hidden variable?;Summing out|Integration over time|Maximum likelihood estimation|Matrix inversion;Summing out;Variable elimination works by multiplying all factors involving the target variable and then summing it out of the resulting factor.;
11;What determines the worst-case time complexity of the Variable Elimination algorithm?;The size of the largest intermediate factor created|The total number of edges in the network|The number of query variables|The number of observed evidence variables;The size of the largest intermediate factor created;The computational cost is dominated by the largest table generated during the pointwise multiplication steps, related to the network's treewidth.;
12;Which of the following is true about the optimal elimination ordering in Variable Elimination?;Finding the optimal elimination ordering is NP-hard|Topological sort always provides the optimal ordering|The ordering does not affect the time complexity|Leaves should always be eliminated last;Finding the optimal elimination ordering is NP-hard;Determining the sequence that produces the smallest intermediate factors is computationally intractable for general graphs.;
13;In Forward Sampling, how is a sample for the entire network generated?;By sampling each variable in topological order based on its parents' sampled values|By sampling variables uniformly at random|By changing one variable at a time based on its Markov Blanket|By forcing evidence variables to be true and weighting the result;By sampling each variable in topological order based on its parents' sampled values;Forward sampling processes the graph from roots to leaves, using the CPTs to simulate an outcome.;
14;What is the main drawback of Rejection Sampling when evidence is present?;It rejects many samples, making it inefficient for rare evidence|It cannot handle continuous variables|It requires exact computation of marginal probabilities first|It forces evidence variables to take incorrect values;It rejects many samples, making it inefficient for rare evidence;If the probability of the evidence is low, the vast majority of generated samples will be thrown away, wasting computation.;
15;How does Likelihood Weighting improve upon Rejection Sampling?;It forces evidence variables to their observed values and assigns a weight to the sample|It uses Markov Chain Monte Carlo to explore the state space|It eliminates the need for topological sorting|It analytically sums out the hidden variables;It forces evidence variables to their observed values and assigns a weight to the sample;By fixing evidence and weighting the sample by the probability of that evidence, it ensures no samples are thrown away.;
16;In Gibbs Sampling, a variable is iteratively resampled given the current state of which other variables?;Its Markov Blanket|Only its parents|All other variables in the network|Only the evidence variables;Its Markov Blanket;In MCMC methods like Gibbs Sampling, a variable's new state is drawn from its conditional distribution given its Markov Blanket.;
17;In the context of parameter learning, what does Maximum Likelihood Estimation (MLE) attempt to maximize?;The probability of the observed data given the parameters|The probability of the parameters given the observed data|The number of edges in the network structure|The structural complexity penalty (BIC);The probability of the observed data given the parameters;MLE finds the parameter values that make the observed training data most probable.;
18;What problem does Laplace Smoothing (add-one smoothing) solve in Parameter Learning?;The zero-count problem where unseen events get assigned a probability of zero|The exponential size of the Conditional Probability Tables|The inability to find the global maximum of the likelihood function|The problem of having hidden variables in the training data;The zero-count problem where unseen events get assigned a probability of zero;Adding a pseudocount ensures that events not present in the training data still have a non-zero probability of occurring.;
19;What is the difference between MLE and MAP (Maximum A Posteriori) estimation?;MAP includes a prior distribution over the parameters|MLE is used for structure learning, MAP for parameter learning|MLE requires complete data, while MAP works only with hidden variables|There is no mathematical difference;MAP includes a prior distribution over the parameters;MLE relies solely on the data to find parameters. MAP incorporates prior beliefs about the parameters, acting as a form of regularization.;
20;When learning the structure of a Bayesian Network, what is the primary purpose of the BIC (Bayesian Information Criterion) score?;To penalize complex models and prevent overfitting|To find the network with the absolute maximum likelihood|To guarantee finding the globally optimal network structure|To increase the number of edges for better accuracy;To penalize complex models and prevent overfitting;The BIC score balances the fit of the model to the data (likelihood) with a penalty term for the number of parameters (complexity), helping to avoid overfitting.;
21;Why is searching the space of all possible DAGs computationally difficult in Structure Learning?;Because the number of possible DAGs is super-exponential in the number of variables|Because cyclic graphs must be included|Because the data is usually continuous|Because Maximum Likelihood scores cannot be computed for DAGs;Because the number of possible DAGs is super-exponential in the number of variables;The search space grows super-exponentially, making exhaustive search impossible for all but the smallest networks.;
22;In a Hidden Markov Model (HMM), what does the 'First-order Markov assumption' state?;The current state depends only on the previous state|The current state depends on all previous states|The observation depends only on the previous observation|The observation depends on the previous state;The current state depends only on the previous state;The first-order Markov assumption implies that the future is independent of the past given the present.;
23;What defines the 'Sensor Model' (or observation model) in an HMM?;P(E_t | X_t)|P(X_t | X_{t-1})|P(X_t | E_t)|P(E_t | E_{t-1});P(E_t | X_t);The sensor model defines the probability of making observation E_t given the current hidden state X_t.;
24;What defines the 'Transition Model' in an HMM?;P(X_t | X_{t-1})|P(E_t | X_t)|P(X_t | E_t)|P(E_t | E_{t-1});P(X_t | X_{t-1});The transition model defines the probability of moving to state X_t given the system was previously in state X_{t-1}.;
25;Which HMM inference task computes the probability distribution of the current state, given all evidence up to the present?;Filtering|Smoothing|Prediction|Most likely explanation;Filtering;Filtering (or state estimation) computes the belief state P(X_t | e_{1:t}), updating the estimate recursively as new evidence arrives.;
26;Which HMM inference task computes the probability distribution of a past state, given all evidence up to the present?;Smoothing|Filtering|Prediction|Most likely explanation;Smoothing;Smoothing estimates a state in the past based on all available evidence up to the current time t, making it more accurate than filtering.;
27;Which algorithm is used in HMMs to find the most likely sequence of hidden states given a sequence of observations?;Viterbi algorithm|Forward algorithm|Backward algorithm|Baum-Welch algorithm;Viterbi algorithm;The Viterbi algorithm is a dynamic programming approach that finds the maximum probability path (sequence of states) that explains the given observation sequence.;
28;What is the purpose of the Forward-Backward algorithm in HMMs?;To perform smoothing by computing probabilities of past states|To find the single most likely path|To learn the transition probabilities from scratch|To generate random sequences of states;To perform smoothing by computing probabilities of past states;The forward pass computes filtering up to a point, and the backward pass brings evidence from the future to smooth the estimate of a specific time step.;
29;If you want to estimate the state of the system multiple time steps into the future, which HMM task are you performing?;Prediction|Filtering|Smoothing|Viterbi decoding;Prediction;Prediction uses the transition model to project the current belief state into the future without any new observations.;
30;How does a Dynamic Bayesian Network (DBN) differ from a standard Hidden Markov Model (HMM)?;DBNs represent states as a set of variables rather than a single discrete variable|DBNs cannot handle time-series data|DBNs assume the Markov property does not hold|HMMs allow continuous states, while DBNs do not;DBNs represent states as a set of variables rather than a single discrete variable;DBNs factorize the state space into multiple interconnected variables, whereas standard HMMs collapse the entire state into one massive discrete variable.;
31;When two variables are strictly independent, what is their joint probability P(X, Y)?;P(X) * P(Y)|P(X) + P(Y)|P(X | Y)|P(Y | X);P(X) * P(Y);By definition, if X and Y are independent, their joint probability is the product of their marginal probabilities.;
32;In standard Exact Inference, what happens to the size of a factor when you sum out a variable?;The dimension of the factor decreases by one|The dimension of the factor increases by one|The factor becomes a scalar|The factor size remains the same;The dimension of the factor decreases by one;Summing out a variable from a factor removes that variable from the factor's scope, effectively projecting it onto the remaining dimensions.;
33;What is 'evidence' in the context of a Bayesian Network query?;Variables whose values are observed and known|Variables we are trying to predict|Hidden variables that must be summed out|The prior probabilities of root nodes;Variables whose values are observed and known;Evidence constitutes the observed facts that we condition our probability query on.;
34;Why is exact inference in Bayesian Networks considered NP-hard?;Because the time required can grow exponentially with the number of variables/treewidth|Because probabilities cannot be perfectly calculated by computers|Because conditional probability tables are impossible to store|Because graphs often contain cycles;Because the time required can grow exponentially with the number of variables/treewidth;For highly connected networks, intermediate factors during variable elimination grow exponentially large.;
35;In a causal chain structure (A -> B -> C), are A and C independent?;No, they are marginally dependent|Yes, they are marginally independent|Yes, they are conditionally independent|They are perfectly correlated;No, they are marginally dependent;Influence flows along the causal chain. A influences B, which influences C, making A and C dependent unless B is observed.;
36;What is the 'burn-in' period in Gibbs Sampling?;Initial samples that are discarded because they are too heavily influenced by the random starting state|The time it takes to compile the network|The process of rejecting samples that don't match the evidence|The final samples that determine the probability;Initial samples that are discarded because they are too heavily influenced by the random starting state;Gibbs sampling requires a warm-up period to converge to the true stationary distribution before samples are counted.;
37;Which inference algorithm is an example of a Markov Chain Monte Carlo (MCMC) method?;Gibbs Sampling|Variable Elimination|Forward Sampling|Likelihood Weighting;Gibbs Sampling;Gibbs sampling constructs a Markov chain whose stationary distribution is the posterior distribution of interest.;
38;In parameter learning with complete data, how is the Maximum Likelihood estimate for a CPT parameter calculated?;By simply counting frequencies in the dataset|By using gradient descent|By performing variable elimination|By applying the Viterbi algorithm;By simply counting frequencies in the dataset;With complete data, MLE is reduced to normalizing the empirical counts of events in the dataset.;
39;What does it mean for data to be 'complete' in the context of Bayesian Network learning?;Every variable's value is observed in every training example|There is an infinite amount of data|There are no noisy measurements|The correct network structure is already known;Every variable's value is observed in every training example;Complete data means there are no missing values or hidden variables, making parameter learning straightforward.;
40;When learning a network structure, what is the 'search space'?;The set of all possible Directed Acyclic Graphs (DAGs) over the given variables|The set of all possible parameter values|The space of all possible elimination orderings|The set of all possible queries;The set of all possible Directed Acyclic Graphs (DAGs) over the given variables;Structure learning algorithms must navigate this space to find the graph that best fits the data.;
41;Why do structure learning algorithms typically use local search methods like Hill Climbing?;Because exhaustive search over all DAGs is computationally impossible for many variables|Because Hill Climbing guarantees finding the global optimum|Because it requires less data|Because local search automatically calculates the parameters;Because exhaustive search over all DAGs is computationally impossible for many variables;The super-exponential size of the DAG space forces the use of greedy or local search algorithms.;
42;In a local search for structure learning, what are the typical operators applied to the graph?;Add edge, delete edge, reverse edge|Sum out, multiply, normalize|Filter, smooth, predict|Forward, backward, reject;Add edge, delete edge, reverse edge;These operators define the 'neighborhood' of the current graph, allowing the algorithm to step to a slightly different structure to check its score.;
43;What does the 'Stationary Assumption' in a dynamic model imply?;The transition model P(X_t | X_{t-1}) is the same for all time steps t|The system never changes its state|Observations are identical at every time step|The Markov blanket includes all future states;The transition model P(X_t | X_{t-1}) is the same for all time steps t;It means the rules governing how the state evolves do not change over time.;
44;In an HMM, what is the 'prior' distribution?;The probability distribution of the initial state, P(X_0)|The probability of the observations|The transition matrix|The sensor model;The probability distribution of the initial state, P(X_0);The prior defines the starting belief of the system at time step 0, before any transitions or observations occur.;
45;Which matrix defines the probability of transitioning from any state i to any state j in an HMM?;The Transition Matrix (A)|The Observation Matrix (B)|The Prior Vector (Pi)|The Covariance Matrix;The Transition Matrix (A);The A matrix encapsulates P(X_t = j | X_{t-1} = i) for all possible states.;
46;Which matrix defines the probability of seeing observation k given the system is in state j in an HMM?;The Observation Matrix (B)|The Transition Matrix (A)|The Prior Vector (Pi)|The Identity Matrix;The Observation Matrix (B);The B matrix (or Emission matrix) encapsulates P(E_t = k | X_t = j) for all states and observations.;
47;What is the primary difference between a Kalman Filter and a discrete Hidden Markov Model?;Kalman Filters handle continuous state spaces with linear Gaussian dynamics, while basic HMMs handle discrete states|Kalman filters do not use the Markov assumption|HMMs are used for smoothing, while Kalman filters are only for prediction|Kalman filters cannot handle noisy observations;Kalman Filters handle continuous state spaces with linear Gaussian dynamics, while basic HMMs handle discrete states;Kalman filters are the continuous, linear-Gaussian counterpart to discrete HMMs.;
48;In a Bayes Net, if nodes X and Y are d-separated by a set of nodes Z, what does this guarantee?;X and Y are conditionally independent given Z|X and Y have no directed path between them|Z is the Markov Blanket of X|X and Y are mutually exclusive;X and Y are conditionally independent given Z;D-separation is the graphical criterion that guarantees conditional independence in the underlying probability distribution.;
49;If a path between two nodes contains a v-structure (X -> Z <- Y) and Z is NOT observed, is the path active or blocked?;Blocked|Active|It depends on the priors|It becomes active only if X is observed;Blocked;In a v-structure, the path is blocked by default. It only becomes active if the common effect Z (or one of its descendants) is observed.;
50;What is the purpose of normalization after calculating the pointwise product of factors during inference?;To ensure the resulting probabilities sum to 1|To eliminate the hidden variables|To convert discrete variables into continuous ones|To apply the BIC penalty;To ensure the resulting probabilities sum to 1;Since intermediate calculations often result in unnormalized likelihoods, dividing by the sum of all entries ensures the final output is a valid probability distribution.;